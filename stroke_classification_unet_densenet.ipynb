{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Stroke Stage Classification using U-Net + DenseNet\n", "**Dataset:** ISLES 2022 (T2A, DWI, ADC)\n", "- Segment ischemic regions with U-Net\n", "- Classify stroke stage with DenseNet (Acute, Subacute, Chronic)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Install dependencies\n", "!pip install nibabel kagglehub tensorflow scikit-learn -q"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Import libraries\n", "import os\n", "import numpy as np\n", "import nibabel as nib\n", "import matplotlib.pyplot as plt\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.metrics import classification_report, f1_score\n", "import tensorflow as tf\n", "from tensorflow.keras import layers, models\n", "from tensorflow.keras.utils import to_categorical"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Download dataset\n", "import kagglehub\n", "path = kagglehub.dataset_download(\"smitgandhi2005/isles-dataset\")\n", "base_path = os.path.join(path, \"ISLES-2022\", \"ISLES-2022\", \"Training\")\n", "\n", "def load_case(case_id):\n", "    case_path = os.path.join(base_path, case_id)\n", "    adc = nib.load(os.path.join(case_path, f\"{case_id}_adc.nii\")).get_fdata()\n", "    dwi = nib.load(os.path.join(case_path, f\"{case_id}_dwi.nii\")).get_fdata()\n", "    flair = nib.load(os.path.join(case_path, f\"{case_id}_flair.nii\")).get_fdata()\n", "    return np.stack([adc, dwi, flair], axis=-1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Define U-Net model\n", "def unet_model(input_shape):\n", "    inputs = layers.Input(input_shape)\n", "    def conv_block(x, filters):\n", "        x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n", "        x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n", "        return x\n", "    def encoder_block(x, filters):\n", "        f = conv_block(x, filters)\n", "        p = layers.MaxPooling2D((2, 2))(f)\n", "        return f, p\n", "    def decoder_block(x, conv_output, filters):\n", "        x = layers.Conv2DTranspose(filters, (2, 2), strides=(2, 2), padding='same')(x)\n", "        x = layers.concatenate([x, conv_output])\n", "        x = conv_block(x, filters)\n", "        return x\n", "\n", "    c1, p1 = encoder_block(inputs, 32)\n", "    c2, p2 = encoder_block(p1, 64)\n", "    c3, p3 = encoder_block(p2, 128)\n", "    bn = conv_block(p3, 256)\n", "    d1 = decoder_block(bn, c3, 128)\n", "    d2 = decoder_block(d1, c2, 64)\n", "    d3 = decoder_block(d2, c1, 32)\n", "    outputs = layers.Conv2D(1, (1, 1), activation=\"sigmoid\")(d3)\n", "    return models.Model(inputs, outputs)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Define DenseNet classifier\n", "from tensorflow.keras.applications import DenseNet121\n", "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n", "def build_classifier(input_shape=(64, 64, 3), num_classes=3):\n", "    base = DenseNet121(include_top=False, input_shape=input_shape, weights=None)\n", "    x = GlobalAveragePooling2D()(base.output)\n", "    output = Dense(num_classes, activation=\"softmax\")(x)\n", "    return models.Model(base.input, output)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.8"}}, "nbformat": 4, "nbformat_minor": 2}